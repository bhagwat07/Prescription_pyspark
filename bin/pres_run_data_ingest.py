import loggingimport logging.configlogging.config.fileConfig(fname='../utils/logging_to_log.conf')logger = logging.getLogger('pres_run_data_ingest.py')def load_file(spark, file_dir, file_format, header, inferSchema):    try:        logger.info('load_file() is started.......!!!!!!!')        if file_format == 'parquet':            df = spark.\                read.\                format(file_format).\                load(file_dir)        elif file_format == 'csv':            df = spark. \                read. \                format(file_format). \                options(header=header).\                options(inferSchema=inferSchema).\                load(file_dir)    except Exception as exp:        logger.error('Error in the method - load_files(). Please check the Stack trace. ',str('exp'))        raise    else:        logger.info(f'The input file {file_dir} is loaded to the dataframe. The load file function is created.')    return df